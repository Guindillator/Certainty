{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "folder = '/home/wilkinsonlab/Escritorio/elsevier/statements/'\n",
    "\n",
    "INPUT_FILE = folder+\"st_45_ground_truth_participants_3l.csv\"\n",
    "\n",
    "texts_test = []  # list of text samples\n",
    "labels_index = {}  # dictionary mapping label name to numeric id\n",
    "labels_test = []  # list of label ids\n",
    "fin = codecs.open(INPUT_FILE,\"r\",  encoding='utf8')\n",
    "for line in fin:\n",
    "    sent, certain = line.strip().split(\"\\t\")\n",
    "    sent = [x for x in nltk.word_tokenize(sent) if x not in stopwords]\n",
    "    texts_test.append(' '.join(sent))\n",
    "    labels_test.append(certain)\n",
    "\n",
    "    \n",
    "print(len(texts_test))\n",
    "print(len(labels_test))\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts_test)\n",
    "\n",
    "texts_test = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "#labels = to_categorical(np.asarray(labels))\n",
    "labels_test = np.asarray(labels_test, dtype=int)\n",
    "labels_test = list(labels_test)\n",
    "for index, item in enumerate(labels_test):\n",
    "    if item == 1:\n",
    "        labels_test[index] = [1,0,0]\n",
    "    elif item == 2:\n",
    "        labels_test[index] = [0,1,0]\n",
    "    else:\n",
    "        labels_test[index] = [0,0,1]\n",
    "labels_test = np.asarray(labels_test)\n",
    "# labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SPLIT = 0.05\n",
    "MAX_NB_WORDS = 6660\n",
    "EMBEDDING_DIM = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(os.path.join(\"/home/wilkinsonlab/Escritorio/elsevier/\", 'dictionary-200.txt')) as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "print('Indexing word vectors.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import nltk\n",
    "import np_utils\n",
    "import pickle\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import numpy\n",
    "from keras.layers.core import Activation, Dense, Dropout, SpatialDropout1D, Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.models import Model\n",
    "from keras.layers.pooling import GlobalMaxPooling1D, MaxPooling1D\n",
    "from keras.layers import LSTM, Bidirectional, Concatenate, GRU, CuDNNGRU, CuDNNLSTM\n",
    "from keras.layers.merge import concatenate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.layers import Embedding\n",
    "from keras import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import regularizers\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "# from pylab import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3221\n",
      "3221\n",
      "Found 6660 unique tokens.\n",
      "('Shape of data tensor:', (3221, 295))\n",
      "('Shape of label tensor:', (3221,))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "puntuacion = 0.80\n",
    "folder = '/home/wilkinsonlab/Escritorio/elsevier/statements/'\n",
    "\n",
    "INPUT_FILE = folder+\"st_3221_ground_truth_train+val_3l.csv\"\n",
    "\n",
    "texts = []  # list of text samples\n",
    "labels_index = {}  # dictionary mapping label name to numeric id\n",
    "labels = []  # list of label ids\n",
    "fin = codecs.open(INPUT_FILE,\"r\",  encoding='utf8')\n",
    "maxlen = 0\n",
    "for line in fin:\n",
    "    sent, certain = line.strip().split(\"\\t\")\n",
    "    sent = [x for x in nltk.word_tokenize(sent) if x not in stopwords]\n",
    "    texts.append(' '.join(sent))\n",
    "    labels.append(certain)\n",
    "\n",
    "    if len(sent) > maxlen:\n",
    "        maxlen = len(sent)\n",
    "fin.close()   \n",
    "print(len(texts))\n",
    "print(len(labels))\n",
    "MAX_SEQUENCE_LENGTH = maxlen\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "#labels = to_categorical(np.asarray(labels))\n",
    "labels = np.asarray(labels, dtype=int)\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing embedding matrix.\n",
      "Found 2255275 word vectors.\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=20, shuffle=True)\n",
    "cvscores = []\n",
    "\n",
    "print('Preparing embedding matrix.')\n",
    "\n",
    "# prepare embedding matrix\n",
    "num_words = min(MAX_NB_WORDS, len(word_index) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NB_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3058 samples, validate on 163 samples\n",
      "Epoch 1/10\n",
      "3058/3058 [==============================] - 35s 11ms/step - loss: 0.4491 - acc: 0.7989 - val_loss: 0.3818 - val_acc: 0.8303\n",
      "Epoch 2/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.3182 - acc: 0.8692 - val_loss: 0.3490 - val_acc: 0.8609\n",
      "Epoch 3/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2994 - acc: 0.8784 - val_loss: 0.3523 - val_acc: 0.8446\n",
      "Epoch 4/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2802 - acc: 0.8897 - val_loss: 0.3155 - val_acc: 0.8650\n",
      "Epoch 5/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2664 - acc: 0.8961 - val_loss: 0.3115 - val_acc: 0.8609\n",
      "Epoch 6/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2624 - acc: 0.8957 - val_loss: 0.3095 - val_acc: 0.8650\n",
      "Epoch 7/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2586 - acc: 0.9012 - val_loss: 0.3033 - val_acc: 0.8732\n",
      "Epoch 8/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2559 - acc: 0.9048 - val_loss: 0.3033 - val_acc: 0.8773\n",
      "Epoch 9/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2507 - acc: 0.9022 - val_loss: 0.2909 - val_acc: 0.8671\n",
      "Epoch 10/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2520 - acc: 0.9020 - val_loss: 0.2853 - val_acc: 0.8814\n",
      "163/163 [==============================] - 0s 2ms/step\n",
      "acc: 88.14%\n",
      "Test score: 0.285, accuracy: 0.881\n",
      "Train on 3058 samples, validate on 163 samples\n",
      "Epoch 1/10\n",
      "3058/3058 [==============================] - 35s 11ms/step - loss: 0.4701 - acc: 0.7807 - val_loss: 0.3306 - val_acc: 0.8650\n",
      "Epoch 2/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.3291 - acc: 0.8679 - val_loss: 0.2847 - val_acc: 0.8937\n",
      "Epoch 3/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.3048 - acc: 0.8762 - val_loss: 0.2591 - val_acc: 0.9080\n",
      "Epoch 4/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2892 - acc: 0.8847 - val_loss: 0.2590 - val_acc: 0.9141\n",
      "Epoch 5/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2756 - acc: 0.8922 - val_loss: 0.2384 - val_acc: 0.9121\n",
      "Epoch 6/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2748 - acc: 0.8876 - val_loss: 0.2379 - val_acc: 0.9100\n",
      "Epoch 7/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2660 - acc: 0.8938 - val_loss: 0.2582 - val_acc: 0.8773\n",
      "Epoch 8/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2573 - acc: 0.8974 - val_loss: 0.2306 - val_acc: 0.9243\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00008: early stopping\n",
      "163/163 [==============================] - 0s 2ms/step\n",
      "acc: 91.21%\n",
      "Test score: 0.238, accuracy: 0.912\n",
      "Train on 3058 samples, validate on 163 samples\n",
      "Epoch 1/10\n",
      "3058/3058 [==============================] - 35s 11ms/step - loss: 0.4729 - acc: 0.7793 - val_loss: 0.3371 - val_acc: 0.8712\n",
      "Epoch 2/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.3330 - acc: 0.8628 - val_loss: 0.3278 - val_acc: 0.8732\n",
      "Epoch 3/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.3130 - acc: 0.8709 - val_loss: 0.3149 - val_acc: 0.8793\n",
      "Epoch 4/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2983 - acc: 0.8802 - val_loss: 0.3288 - val_acc: 0.8732\n",
      "Epoch 5/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2812 - acc: 0.8859 - val_loss: 0.3024 - val_acc: 0.8916\n",
      "Epoch 6/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2737 - acc: 0.8913 - val_loss: 0.3155 - val_acc: 0.8814\n",
      "Epoch 7/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2748 - acc: 0.8899 - val_loss: 0.3257 - val_acc: 0.8793\n",
      "Epoch 8/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2689 - acc: 0.8940 - val_loss: 0.3177 - val_acc: 0.8753\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00008: early stopping\n",
      "163/163 [==============================] - 0s 2ms/step\n",
      "acc: 89.16%\n",
      "Test score: 0.302, accuracy: 0.892\n",
      "Train on 3058 samples, validate on 163 samples\n",
      "Epoch 1/10\n",
      "3058/3058 [==============================] - 35s 11ms/step - loss: 0.4833 - acc: 0.7714 - val_loss: 0.3689 - val_acc: 0.8446\n",
      "Epoch 2/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.3238 - acc: 0.8661 - val_loss: 0.3488 - val_acc: 0.8487\n",
      "Epoch 3/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2948 - acc: 0.8799 - val_loss: 0.3022 - val_acc: 0.8650\n",
      "Epoch 4/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2856 - acc: 0.8799 - val_loss: 0.3376 - val_acc: 0.8589\n",
      "Epoch 5/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2759 - acc: 0.8839 - val_loss: 0.3225 - val_acc: 0.8814\n",
      "Epoch 6/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2640 - acc: 0.8914 - val_loss: 0.3173 - val_acc: 0.8814\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00006: early stopping\n",
      "163/163 [==============================] - 0s 2ms/step\n",
      "acc: 86.50%\n",
      "Test score: 0.302, accuracy: 0.865\n",
      "Train on 3058 samples, validate on 163 samples\n",
      "Epoch 1/10\n",
      "3058/3058 [==============================] - 35s 11ms/step - loss: 0.4729 - acc: 0.7802 - val_loss: 0.3917 - val_acc: 0.8282\n",
      "Epoch 2/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.3281 - acc: 0.8643 - val_loss: 0.3729 - val_acc: 0.8507\n",
      "Epoch 3/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.3025 - acc: 0.8750 - val_loss: 0.4310 - val_acc: 0.8323\n",
      "Epoch 4/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2900 - acc: 0.8785 - val_loss: 0.3345 - val_acc: 0.8548\n",
      "Epoch 5/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2714 - acc: 0.8866 - val_loss: 0.3193 - val_acc: 0.8569\n",
      "Epoch 6/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2630 - acc: 0.8937 - val_loss: 0.3304 - val_acc: 0.8589\n",
      "Epoch 7/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2558 - acc: 0.8994 - val_loss: 0.3207 - val_acc: 0.8630\n",
      "Epoch 8/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2531 - acc: 0.9009 - val_loss: 0.3300 - val_acc: 0.8569\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00008: early stopping\n",
      "163/163 [==============================] - 0s 2ms/step\n",
      "acc: 85.69%\n",
      "Test score: 0.319, accuracy: 0.857\n",
      "Train on 3058 samples, validate on 163 samples\n",
      "Epoch 1/10\n",
      "3058/3058 [==============================] - 35s 11ms/step - loss: 0.4411 - acc: 0.7964 - val_loss: 0.3539 - val_acc: 0.8528\n",
      "Epoch 2/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.3286 - acc: 0.8629 - val_loss: 0.3172 - val_acc: 0.8732\n",
      "Epoch 3/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.3069 - acc: 0.8684 - val_loss: 0.2918 - val_acc: 0.8773\n",
      "Epoch 4/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2904 - acc: 0.8774 - val_loss: 0.2877 - val_acc: 0.8875\n",
      "Epoch 5/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2730 - acc: 0.8890 - val_loss: 0.2536 - val_acc: 0.8978\n",
      "Epoch 6/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2630 - acc: 0.8956 - val_loss: 0.2416 - val_acc: 0.9039\n",
      "Epoch 7/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2592 - acc: 0.8961 - val_loss: 0.2494 - val_acc: 0.9018\n",
      "Epoch 8/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2531 - acc: 0.8954 - val_loss: 0.2556 - val_acc: 0.9039\n",
      "Epoch 9/10\n",
      "3058/3058 [==============================] - 33s 11ms/step - loss: 0.2441 - acc: 0.9029 - val_loss: 0.2493 - val_acc: 0.8916\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00009: early stopping\n",
      "163/163 [==============================] - 0s 2ms/step\n",
      "acc: 90.39%\n",
      "Test score: 0.242, accuracy: 0.904\n",
      "Train on 3059 samples, validate on 162 samples\n",
      "Epoch 1/10\n",
      "3059/3059 [==============================] - 36s 12ms/step - loss: 0.4671 - acc: 0.7756 - val_loss: 0.3678 - val_acc: 0.8539\n",
      "Epoch 2/10\n",
      "3059/3059 [==============================] - 33s 11ms/step - loss: 0.3285 - acc: 0.8602 - val_loss: 0.3207 - val_acc: 0.8621\n",
      "Epoch 3/10\n",
      "3059/3059 [==============================] - 33s 11ms/step - loss: 0.3120 - acc: 0.8761 - val_loss: 0.2898 - val_acc: 0.8930\n",
      "Epoch 4/10\n",
      "3059/3059 [==============================] - 33s 11ms/step - loss: 0.2921 - acc: 0.8801 - val_loss: 0.3044 - val_acc: 0.8765\n",
      "Epoch 5/10\n",
      "3059/3059 [==============================] - 33s 11ms/step - loss: 0.2755 - acc: 0.8860 - val_loss: 0.2718 - val_acc: 0.9012\n",
      "Epoch 6/10\n",
      "3059/3059 [==============================] - 33s 11ms/step - loss: 0.2688 - acc: 0.8906 - val_loss: 0.2888 - val_acc: 0.8992\n",
      "Epoch 7/10\n",
      "3059/3059 [==============================] - 33s 11ms/step - loss: 0.2610 - acc: 0.8919 - val_loss: 0.2998 - val_acc: 0.8889\n",
      "Epoch 8/10\n",
      "3059/3059 [==============================] - 33s 11ms/step - loss: 0.2554 - acc: 0.9005 - val_loss: 0.2768 - val_acc: 0.9115\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00008: early stopping\n",
      "162/162 [==============================] - 0s 2ms/step\n",
      "acc: 90.12%\n",
      "Test score: 0.272, accuracy: 0.901\n",
      "Train on 3060 samples, validate on 161 samples\n",
      "Epoch 1/10\n",
      "3060/3060 [==============================] - 36s 12ms/step - loss: 0.4540 - acc: 0.7901 - val_loss: 0.2969 - val_acc: 0.8820\n",
      "Epoch 2/10\n",
      "3060/3060 [==============================] - 33s 11ms/step - loss: 0.3291 - acc: 0.8635 - val_loss: 0.2671 - val_acc: 0.8986\n",
      "Epoch 3/10\n",
      "3060/3060 [==============================] - 33s 11ms/step - loss: 0.3116 - acc: 0.8679 - val_loss: 0.2642 - val_acc: 0.8986\n",
      "Epoch 4/10\n",
      "3060/3060 [==============================] - 33s 11ms/step - loss: 0.2892 - acc: 0.8832 - val_loss: 0.2419 - val_acc: 0.9089\n",
      "Epoch 5/10\n",
      "3060/3060 [==============================] - 33s 11ms/step - loss: 0.2810 - acc: 0.8869 - val_loss: 0.2489 - val_acc: 0.9110\n",
      "Epoch 6/10\n",
      "3060/3060 [==============================] - 33s 11ms/step - loss: 0.2677 - acc: 0.8922 - val_loss: 0.2680 - val_acc: 0.8820\n",
      "Epoch 7/10\n",
      "3060/3060 [==============================] - 33s 11ms/step - loss: 0.2639 - acc: 0.8952 - val_loss: 0.2315 - val_acc: 0.9234\n",
      "Epoch 8/10\n",
      "3060/3060 [==============================] - 33s 11ms/step - loss: 0.2579 - acc: 0.8985 - val_loss: 0.2345 - val_acc: 0.9068\n",
      "Epoch 9/10\n",
      "3060/3060 [==============================] - 33s 11ms/step - loss: 0.2557 - acc: 0.8985 - val_loss: 0.2230 - val_acc: 0.9255\n",
      "Epoch 10/10\n",
      "3060/3060 [==============================] - 33s 11ms/step - loss: 0.2537 - acc: 0.9000 - val_loss: 0.2431 - val_acc: 0.9068\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00010: early stopping\n",
      "161/161 [==============================] - 0s 2ms/step\n",
      "acc: 92.34%\n",
      "Test score: 0.232, accuracy: 0.923\n",
      "Train on 3061 samples, validate on 160 samples\n",
      "Epoch 1/10\n",
      "3061/3061 [==============================] - 36s 12ms/step - loss: 0.4685 - acc: 0.7779 - val_loss: 0.3166 - val_acc: 0.8792\n",
      "Epoch 2/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.3351 - acc: 0.8593 - val_loss: 0.2715 - val_acc: 0.8833\n",
      "Epoch 3/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.3131 - acc: 0.8689 - val_loss: 0.2660 - val_acc: 0.8979\n",
      "Epoch 4/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.3009 - acc: 0.8787 - val_loss: 0.2540 - val_acc: 0.9104\n",
      "Epoch 5/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2866 - acc: 0.8841 - val_loss: 0.2422 - val_acc: 0.9104\n",
      "Epoch 6/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2778 - acc: 0.8907 - val_loss: 0.2652 - val_acc: 0.9104\n",
      "Epoch 7/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2780 - acc: 0.8865 - val_loss: 0.2422 - val_acc: 0.9063\n",
      "Epoch 8/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2679 - acc: 0.8910 - val_loss: 0.2363 - val_acc: 0.9104\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00008: early stopping\n",
      "160/160 [==============================] - 0s 2ms/step\n",
      "acc: 91.04%\n",
      "Test score: 0.242, accuracy: 0.910\n",
      "Train on 3061 samples, validate on 160 samples\n",
      "Epoch 1/10\n",
      "3061/3061 [==============================] - 36s 12ms/step - loss: 0.4557 - acc: 0.7890 - val_loss: 0.3311 - val_acc: 0.8792\n",
      "Epoch 2/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.3276 - acc: 0.8621 - val_loss: 0.2710 - val_acc: 0.8771\n",
      "Epoch 3/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2995 - acc: 0.8739 - val_loss: 0.2691 - val_acc: 0.8688\n",
      "Epoch 4/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2827 - acc: 0.8798 - val_loss: 0.2530 - val_acc: 0.9000\n",
      "Epoch 5/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2751 - acc: 0.8893 - val_loss: 0.2352 - val_acc: 0.9083\n",
      "Epoch 6/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2675 - acc: 0.8988 - val_loss: 0.2285 - val_acc: 0.9188\n",
      "Epoch 7/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2621 - acc: 0.8982 - val_loss: 0.2264 - val_acc: 0.9208\n",
      "Epoch 8/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2469 - acc: 0.9057 - val_loss: 0.2385 - val_acc: 0.9083\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00008: early stopping\n",
      "160/160 [==============================] - 0s 2ms/step\n",
      "acc: 90.83%\n",
      "Test score: 0.235, accuracy: 0.908\n",
      "Train on 3061 samples, validate on 160 samples\n",
      "Epoch 1/10\n",
      "3061/3061 [==============================] - 37s 12ms/step - loss: 0.4605 - acc: 0.7804 - val_loss: 0.3485 - val_acc: 0.8583\n",
      "Epoch 2/10\n",
      "3061/3061 [==============================] - 34s 11ms/step - loss: 0.3307 - acc: 0.8605 - val_loss: 0.3293 - val_acc: 0.8604\n",
      "Epoch 3/10\n",
      "3061/3061 [==============================] - 34s 11ms/step - loss: 0.3076 - acc: 0.8724 - val_loss: 0.3289 - val_acc: 0.8646\n",
      "Epoch 4/10\n",
      "3061/3061 [==============================] - 34s 11ms/step - loss: 0.2911 - acc: 0.8793 - val_loss: 0.3176 - val_acc: 0.8396\n",
      "Epoch 5/10\n",
      "3061/3061 [==============================] - 34s 11ms/step - loss: 0.2699 - acc: 0.8943 - val_loss: 0.3028 - val_acc: 0.8729\n",
      "Epoch 6/10\n",
      "3061/3061 [==============================] - 34s 11ms/step - loss: 0.2674 - acc: 0.8950 - val_loss: 0.2710 - val_acc: 0.8917\n",
      "Epoch 7/10\n",
      "3061/3061 [==============================] - 34s 11ms/step - loss: 0.2582 - acc: 0.9013 - val_loss: 0.2754 - val_acc: 0.8917\n",
      "Epoch 8/10\n",
      "3061/3061 [==============================] - 34s 11ms/step - loss: 0.2564 - acc: 0.8979 - val_loss: 0.2928 - val_acc: 0.8750\n",
      "Epoch 9/10\n",
      "3061/3061 [==============================] - 34s 11ms/step - loss: 0.2518 - acc: 0.9044 - val_loss: 0.2915 - val_acc: 0.8896\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00009: early stopping\n",
      "160/160 [==============================] - 0s 2ms/step\n",
      "acc: 89.17%\n",
      "Test score: 0.271, accuracy: 0.892\n",
      "Train on 3061 samples, validate on 160 samples\n",
      "Epoch 1/10\n",
      "3061/3061 [==============================] - 37s 12ms/step - loss: 0.4479 - acc: 0.7923 - val_loss: 0.3551 - val_acc: 0.8563\n",
      "Epoch 2/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.3296 - acc: 0.8631 - val_loss: 0.3444 - val_acc: 0.8604\n",
      "Epoch 3/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.3125 - acc: 0.8729 - val_loss: 0.3350 - val_acc: 0.8583\n",
      "Epoch 4/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2978 - acc: 0.8790 - val_loss: 0.3226 - val_acc: 0.8750\n",
      "Epoch 5/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2817 - acc: 0.8896 - val_loss: 0.3041 - val_acc: 0.8667\n",
      "Epoch 6/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2688 - acc: 0.8962 - val_loss: 0.3011 - val_acc: 0.8813\n",
      "Epoch 7/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2617 - acc: 0.8984 - val_loss: 0.2976 - val_acc: 0.8771\n",
      "Epoch 8/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2568 - acc: 0.9004 - val_loss: 0.3021 - val_acc: 0.8813\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00008: early stopping\n",
      "160/160 [==============================] - 0s 2ms/step\n",
      "acc: 86.67%\n",
      "Test score: 0.304, accuracy: 0.867\n",
      "Train on 3061 samples, validate on 160 samples\n",
      "Epoch 1/10\n",
      "3061/3061 [==============================] - 37s 12ms/step - loss: 0.4593 - acc: 0.7828 - val_loss: 0.2960 - val_acc: 0.8750\n",
      "Epoch 2/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.3244 - acc: 0.8654 - val_loss: 0.2906 - val_acc: 0.8771\n",
      "Epoch 3/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.3017 - acc: 0.8792 - val_loss: 0.2473 - val_acc: 0.9063\n",
      "Epoch 4/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2822 - acc: 0.8893 - val_loss: 0.2430 - val_acc: 0.9083\n",
      "Epoch 5/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2721 - acc: 0.8918 - val_loss: 0.2302 - val_acc: 0.9146\n",
      "Epoch 6/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2668 - acc: 0.8931 - val_loss: 0.2548 - val_acc: 0.9063\n",
      "Epoch 7/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2628 - acc: 0.8974 - val_loss: 0.2621 - val_acc: 0.9125\n",
      "Epoch 8/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2560 - acc: 0.9010 - val_loss: 0.2248 - val_acc: 0.9167\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00008: early stopping\n",
      "160/160 [==============================] - 0s 2ms/step\n",
      "acc: 91.46%\n",
      "Test score: 0.230, accuracy: 0.915\n",
      "Train on 3061 samples, validate on 160 samples\n",
      "Epoch 1/10\n",
      "3061/3061 [==============================] - 38s 12ms/step - loss: 0.4598 - acc: 0.7851 - val_loss: 0.3362 - val_acc: 0.8667\n",
      "Epoch 2/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.3192 - acc: 0.8687 - val_loss: 0.3274 - val_acc: 0.8667\n",
      "Epoch 3/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2939 - acc: 0.8820 - val_loss: 0.2802 - val_acc: 0.9063\n",
      "Epoch 4/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2813 - acc: 0.8863 - val_loss: 0.3090 - val_acc: 0.8750\n",
      "Epoch 5/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2683 - acc: 0.8921 - val_loss: 0.2942 - val_acc: 0.8708\n",
      "Epoch 6/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2614 - acc: 0.8951 - val_loss: 0.2743 - val_acc: 0.8979\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00006: early stopping\n",
      "160/160 [==============================] - 0s 2ms/step\n",
      "acc: 90.63%\n",
      "Test score: 0.280, accuracy: 0.906\n",
      "Train on 3061 samples, validate on 160 samples\n",
      "Epoch 1/10\n",
      "3061/3061 [==============================] - 38s 12ms/step - loss: 0.4649 - acc: 0.7839 - val_loss: 0.3442 - val_acc: 0.8688\n",
      "Epoch 2/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.3297 - acc: 0.8639 - val_loss: 0.3385 - val_acc: 0.8667\n",
      "Epoch 3/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.3003 - acc: 0.8726 - val_loss: 0.2936 - val_acc: 0.8792\n",
      "Epoch 4/10\n",
      "3061/3061 [==============================] - 34s 11ms/step - loss: 0.2832 - acc: 0.8859 - val_loss: 0.2911 - val_acc: 0.8813\n",
      "Epoch 5/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2774 - acc: 0.8907 - val_loss: 0.2893 - val_acc: 0.8750\n",
      "Epoch 6/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2694 - acc: 0.8948 - val_loss: 0.3934 - val_acc: 0.8313\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00006: early stopping\n",
      "160/160 [==============================] - 0s 2ms/step\n",
      "acc: 87.92%\n",
      "Test score: 0.294, accuracy: 0.879\n",
      "Train on 3061 samples, validate on 160 samples\n",
      "Epoch 1/10\n",
      "3061/3061 [==============================] - 38s 13ms/step - loss: 0.4718 - acc: 0.7747 - val_loss: 0.3449 - val_acc: 0.8438\n",
      "Epoch 2/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.3299 - acc: 0.8620 - val_loss: 0.2816 - val_acc: 0.8938\n",
      "Epoch 3/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2968 - acc: 0.8788 - val_loss: 0.2768 - val_acc: 0.8792\n",
      "Epoch 4/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2827 - acc: 0.8838 - val_loss: 0.3148 - val_acc: 0.8708\n",
      "Epoch 5/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2737 - acc: 0.8911 - val_loss: 0.2754 - val_acc: 0.8958\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00005: early stopping\n",
      "160/160 [==============================] - 0s 2ms/step\n",
      "acc: 89.37%\n",
      "Test score: 0.282, accuracy: 0.894\n",
      "Train on 3061 samples, validate on 160 samples\n",
      "Epoch 1/10\n",
      "3061/3061 [==============================] - 39s 13ms/step - loss: 0.4412 - acc: 0.7972 - val_loss: 0.3925 - val_acc: 0.8542\n",
      "Epoch 2/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.3278 - acc: 0.8651 - val_loss: 0.3173 - val_acc: 0.8833\n",
      "Epoch 3/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.3057 - acc: 0.8722 - val_loss: 0.6043 - val_acc: 0.6833\n",
      "Epoch 4/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2901 - acc: 0.8802 - val_loss: 0.2935 - val_acc: 0.8917\n",
      "Epoch 5/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2780 - acc: 0.8834 - val_loss: 0.2833 - val_acc: 0.8854\n",
      "Epoch 6/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2713 - acc: 0.8910 - val_loss: 0.2764 - val_acc: 0.9021\n",
      "Epoch 7/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2629 - acc: 0.8951 - val_loss: 0.2824 - val_acc: 0.9000\n",
      "Epoch 8/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2546 - acc: 0.8989 - val_loss: 0.2592 - val_acc: 0.9042\n",
      "Epoch 9/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2515 - acc: 0.9007 - val_loss: 0.2788 - val_acc: 0.9042\n",
      "Epoch 10/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2439 - acc: 0.9040 - val_loss: 0.2694 - val_acc: 0.9083\n",
      "160/160 [==============================] - 0s 2ms/step\n",
      "acc: 90.83%\n",
      "Test score: 0.269, accuracy: 0.908\n",
      "Train on 3061 samples, validate on 160 samples\n",
      "Epoch 1/10\n",
      "3061/3061 [==============================] - 39s 13ms/step - loss: 0.4478 - acc: 0.7956 - val_loss: 0.3762 - val_acc: 0.8333\n",
      "Epoch 2/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.3336 - acc: 0.8593 - val_loss: 0.3682 - val_acc: 0.8229\n",
      "Epoch 3/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.3057 - acc: 0.8776 - val_loss: 0.3568 - val_acc: 0.8354\n",
      "Epoch 4/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2845 - acc: 0.8874 - val_loss: 0.3393 - val_acc: 0.8375\n",
      "Epoch 5/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2746 - acc: 0.8920 - val_loss: 0.3397 - val_acc: 0.8417\n",
      "Epoch 6/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2658 - acc: 0.8952 - val_loss: 0.3438 - val_acc: 0.8396\n",
      "Epoch 7/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2597 - acc: 0.9016 - val_loss: 0.3431 - val_acc: 0.8542\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00007: early stopping\n",
      "160/160 [==============================] - 0s 2ms/step\n",
      "acc: 83.75%\n",
      "Test score: 0.339, accuracy: 0.838\n",
      "Train on 3061 samples, validate on 160 samples\n",
      "Epoch 1/10\n",
      "3061/3061 [==============================] - 40s 13ms/step - loss: 0.4671 - acc: 0.7767 - val_loss: 0.3621 - val_acc: 0.8500\n",
      "Epoch 2/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.3304 - acc: 0.8627 - val_loss: 0.3971 - val_acc: 0.8167\n",
      "Epoch 3/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.3004 - acc: 0.8762 - val_loss: 0.3281 - val_acc: 0.8729\n",
      "Epoch 4/10\n",
      "3061/3061 [==============================] - 34s 11ms/step - loss: 0.2811 - acc: 0.8806 - val_loss: 0.2910 - val_acc: 0.8896\n",
      "Epoch 5/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2675 - acc: 0.8889 - val_loss: 0.3264 - val_acc: 0.8813\n",
      "Epoch 6/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2661 - acc: 0.8965 - val_loss: 0.2726 - val_acc: 0.9000\n",
      "Epoch 7/10\n",
      "3061/3061 [==============================] - 34s 11ms/step - loss: 0.2569 - acc: 0.8995 - val_loss: 0.2757 - val_acc: 0.8896\n",
      "Epoch 8/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2637 - acc: 0.8946 - val_loss: 0.2980 - val_acc: 0.8875\n",
      "Epoch 9/10\n",
      "3061/3061 [==============================] - 33s 11ms/step - loss: 0.2529 - acc: 0.8998 - val_loss: 0.2673 - val_acc: 0.8917\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00009: early stopping\n",
      "160/160 [==============================] - 0s 2ms/step\n",
      "acc: 90.00%\n",
      "Test score: 0.273, accuracy: 0.900\n",
      "Train on 3061 samples, validate on 160 samples\n",
      "Epoch 1/10\n",
      "3061/3061 [==============================] - 40s 13ms/step - loss: 0.4594 - acc: 0.7843 - val_loss: 0.3376 - val_acc: 0.8646\n",
      "Epoch 2/10\n",
      "3061/3061 [==============================] - 34s 11ms/step - loss: 0.3259 - acc: 0.8638 - val_loss: 0.2936 - val_acc: 0.8813\n",
      "Epoch 3/10\n",
      "3061/3061 [==============================] - 34s 11ms/step - loss: 0.3031 - acc: 0.8766 - val_loss: 0.2979 - val_acc: 0.8896\n",
      "Epoch 4/10\n",
      "3061/3061 [==============================] - 34s 11ms/step - loss: 0.2904 - acc: 0.8895 - val_loss: 0.2849 - val_acc: 0.8833\n",
      "Epoch 5/10\n",
      "3061/3061 [==============================] - 34s 11ms/step - loss: 0.2834 - acc: 0.8871 - val_loss: 0.2608 - val_acc: 0.8917\n",
      "Epoch 6/10\n",
      "3061/3061 [==============================] - 34s 11ms/step - loss: 0.2726 - acc: 0.8898 - val_loss: 0.2608 - val_acc: 0.8917\n",
      "Epoch 7/10\n",
      "3061/3061 [==============================] - 34s 11ms/step - loss: 0.2676 - acc: 0.8919 - val_loss: 0.2494 - val_acc: 0.9000\n",
      "Epoch 8/10\n",
      "3061/3061 [==============================] - 34s 11ms/step - loss: 0.2570 - acc: 0.8985 - val_loss: 0.2714 - val_acc: 0.8958\n",
      "Epoch 9/10\n",
      "3061/3061 [==============================] - 34s 11ms/step - loss: 0.2575 - acc: 0.8995 - val_loss: 0.2678 - val_acc: 0.8958\n",
      "Epoch 10/10\n",
      "3061/3061 [==============================] - 34s 11ms/step - loss: 0.2538 - acc: 0.9007 - val_loss: 0.2481 - val_acc: 0.9000\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00010: early stopping\n",
      "160/160 [==============================] - 0s 2ms/step\n",
      "acc: 90.00%\n",
      "Test score: 0.249, accuracy: 0.900\n",
      "89.26% (+/- 2.14%)\n"
     ]
    }
   ],
   "source": [
    "cvscores = []\n",
    "np.random.seed(1)\n",
    "historial = []\n",
    "train_test= []\n",
    "contador = 0\n",
    "for train, test in kfold.split(data, labels):\n",
    "    if contador == 0:\n",
    "        labels = list(labels)\n",
    "        for index, item in enumerate(labels):\n",
    "            if item == 1:\n",
    "                labels[index] = [1,0,0]\n",
    "            elif item == 2:\n",
    "                labels[index] = [0,1,0]\n",
    "            else:\n",
    "                labels[index] = [0,0,1]\n",
    "        labels = np.asarray(labels)\n",
    "        contador = contador + 1\n",
    "    train_test.append([train,test])\n",
    "    #     reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, mode='auto', patience=3, min_lr=0.002)\n",
    "    stop = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3, verbose=1, mode='auto', restore_best_weights=True)\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(num_words, EMBEDDING_DIM, \n",
    "                            input_length=MAX_SEQUENCE_LENGTH))\n",
    "    model.layers[0].set_weights([embedding_matrix])\n",
    "    model.layers[0].trainable = False\n",
    "    model.add(Dense(300,kernel_regularizer=regularizers.l1(0.000001)))\n",
    "    model.add(Dropout(0.35))\n",
    "    model.add(Dense(200,kernel_regularizer=regularizers.l1(0.000001)))\n",
    "    model.add(Dropout(0.35))\n",
    "    model.add(Dense(100,kernel_regularizer=regularizers.l1(0.000001)))\n",
    "    model.add((LSTM(50, dropout=0.1, recurrent_dropout=0.1)))#, kernel_regularizer=regularizers.l1(0.00001))))\n",
    "    model.add(Dense(3,kernel_regularizer=regularizers.l1(0.000001)))\n",
    "    model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", \n",
    "                    metrics=[\"accuracy\"])\n",
    "\n",
    "    history = model.fit(data[train], labels[train], batch_size=20, \n",
    "                            epochs=10\n",
    "                           ,validation_data=(data[test], labels[test]), callbacks=[stop])\n",
    "    historial.append(history)\n",
    "    # evaluate model\n",
    "    scores = model.evaluate(data[test], labels[test], verbose=1)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    print(\"Test score: {:.3f}, accuracy: {:.3f}\".format(scores[0], scores[1]))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.26% (+/- 2.14%)\n",
      "[88.1390596094307, 91.20654474738186, 89.16155666661409, 86.50306869138238, 85.68507275698374, 90.38854727715803, 90.12345601747064, 92.33954648793853, 91.04166746139526, 90.83333492279053, 89.16666746139526, 86.66666626930237, 91.45833253860474, 90.6250011920929, 87.91666746139526, 89.3749988079071, 90.83333492279053, 83.7500011920929, 90.0000011920929, 90.0000011920929]\n"
     ]
    }
   ],
   "source": [
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "print cvscores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
